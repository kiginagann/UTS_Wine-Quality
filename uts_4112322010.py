# -*- coding: utf-8 -*-
"""UTS_4112322010.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vdD953HSs1LErwDbdyhFXrfshZ7Hfeb-

#**UTS MACHINE LEARNING**


*   NAMA : KINANTI ANGGRAENI
*   NIM : 4112322010

#**Import Libraries**
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
from termcolor import colored

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB

"""# **Data**

## Collecting Data
"""

data_train = pd.read_csv('/content/drive/MyDrive/data_training.csv')
data_train.head()

"""## Data Information"""

data_train.info()

data_train.describe().T.style.background_gradient(axis=0)

"""<div style="border-radius:20px; padding: 15px; font-size:100%; text-align:left; background-image: url(https://i.postimg.cc/0jG2Q5Nm/Adobe-Stock-522250922-Preview-Medium.jpg)">
    
<h2 style='border:0; border-radius: 15px; font-weight: 800; color:#9b006e; font-size:280%'><center> Attribute Information
</center></h2>

|Feature|Penjelasan|
|-------|-------|
|**fixed acidity**|Kadar asam-asam tidak mudah menguap yang terdapat dalam anggur|
|**volatile acidity**|Jumlah asam asetat dalam anggur|
|**citric acid**|Jumlah asam sitrat dalam anggur|
|**residual sugar**|Jumlah gula yang tersisa setelah proses fermentasi berhenti|
|**chlorides**|Kadar garam dalam anggur|
|**free sulfur dioxide**|Jumlah sulfur dioksida dalam bentuk bebas dalam anggur.|
|**total sulfur dioxide**|Jumlah total sulfur dioksida dalam anggur, termasuk bentuk bebas dan terikat.|
|**density**|Ukuran seberapa padat suatu zat dikemas.|
|**PH**|Ukuran tingkat keasaman atau kebasaan anggur pada skala 0 (sangat asam) hingga 14 (sangat basa).; sebagian anggur memiliki pH 3-4|
|**sulphates**|Jumlah garam asam sulfat dalam anggur. |
|**Alcohol**|Persentase kandungan alkohol dalam anggur berdasarkan volume|
|**quality**|Variabel target atau output yang menunjukkan kualitas anggur berdasarkan data sensorik|
|**ID**|Nomor unik yang digunakan untuk mengidentifikasi setiap sampel data secara individual|

# **Data Preprocessing**

## Missing Values Handling
"""

data_train.isna().sum()

"""✅tidak terdapat missing values

## Visualization and Plots
"""

data_train.rename(columns = {"fixed acidity": "fixed_acidity",
                       "volatile acidity": "volatile_acidity",
                       "citric acid": "citric_acid",
                       "residual sugar": "residual_sugar",
                       "chlorides": "chlorides",
                       "free sulfur dioxide": "free_sulfur_dioxide",
                       "total sulfur dioxide": "total_sulfur_dioxide"},
            inplace = True)

""".rename() agar nama-nama kolom lebih bersih, Pythonic, dan siap dipakai untuk analisis"""

columns = list(data_train.columns)

columns = [col for col in data_train.columns if col not in ['quality', 'Id']]

fig, ax = plt.subplots(len(columns), 2, figsize=(15, 5 * len(columns)))
plt.subplots_adjust(hspace=0.5)

for i in range(len(columns)):
    sns.boxplot(x=columns[i], data=data_train, ax=ax[i, 0])
    sns.scatterplot(x=columns[i], y='quality', data=data_train, hue='quality', ax=ax[i, 1])

"""##Insight Per Fitur

**1. Fixed Acidity**
- Banyak outlier di atas 11.
- Tidak terlihat tren jelas terhadap quality, distribusi rata.

**2. Volatile Acidity**
- Terlihat tren negatif: nilai rendah cenderung memiliki kualitas tinggi.
- Kualitas 7–8 terkumpul di volatile_acidity rendah

**3. Citric Acid**
- Kualitas 7–8 banyak muncul di nilai citric_acid tinggi → korelasi positif terlihat.

**4. Residual Sugar**
- Banyak outlier.
- Distribusi terhadap quality cukup flat, sedikit pengaruh (konfirmasi juga di heatmap).

**5. Chlorides**
- Banyak outlier tinggi, terutama >0.2.
- Kualitas tinggi lebih banyak muncul pada nilai rendah

**6. Free Sulfur Dioxide & Total Sulfur Dioxide**
- Banyak outlier.
- Distribusinya terhadap quality cenderung menyebar → pengaruh kecil

**7. Density**
- Terdistribusi ketat (range kecil), tapi terlihat tren: kualitas tinggi condong ke density rendah → korelasi negatif.

**8. pH**
- Tidak banyak outlier.
- Tidak terlalu terlihat tren jelas terhadap quality.

**9. Sulphates**
- Terlihat: kualitas tinggi muncul lebih banyak di sulphates tinggi → korelasi positif lemah ke sedang.

**10. Alcohol**
- Kualitas 7–8 dominan pada nilai alkohol tinggi
- Ini sangat konsisten dengan korelasi +0.47 → fitur paling signifikan
"""

corr = data_train.drop(columns='Id').corr()
plt.figure(figsize=(9, 6))
sns.heatmap(corr, annot=True, fmt='.2f', linewidth=0.5, cmap='Purples', mask=np.triu(corr))
plt.show()

"""## Analisis Plots

➡️Korelasi Terkuat terhadap quality:

- alcohol → 0.47

konsisten dengan hasil visualisasi sebelumnya, semakin tinggi kandungan alkohol, cenderung semakin tinggi kualitas anggur.

- volatile acidity → -0.43

semakin tinggi tingkat keasaman volatil, kualitas cenderung menurun.
"""

sns.pairplot(data_train.drop(columns='Id'), hue='quality', corner=True, palette='Purples')

"""## Target Categorizing

"""

data_train.quality.unique()

"""## Normalization"""

X_temp = data_train.drop(columns=['quality', 'Id'])
y = data_train['quality']

"""➡️ menormalisasi data X menggunakan MinMaxScaler dengan rentang [0, 1] untuk menskalakan semua fitur numerik dalam dataset"""

scaler = MinMaxScaler(feature_range=(0, 1)).fit_transform(X_temp)
X = pd.DataFrame(scaler, columns=X_temp.columns)
X.describe().T.style.background_gradient(axis=0, cmap='Purples')

"""#**Modeling**

## Initialization
"""

def plot_confusion_matrix(y_test, y_prediction):
    '''Plotting Confusion Matrix'''
    cm = metrics.confusion_matrix(y_test, y_prediction)
    ax = plt.subplot()
    ax = sns.heatmap(cm, annot=True, fmt='', cmap="Purples")
    ax.set_xlabel('Prediced labels', fontsize=18)
    ax.set_ylabel('True labels', fontsize=18)
    ax.set_title('Confusion Matrix', fontsize=25)
    ax.xaxis.set_ticklabels(y_test.unique())
    ax.yaxis.set_ticklabels(y_test.unique())
    plt.show()

def clfr_plot(y_test, y_pred) :
    ''' Plotting Classification report'''
    cr = pd.DataFrame(metrics.classification_report(y_test, y_pred_rf, digits=3,
                                            output_dict=True)).T
    cr.drop(columns='support', inplace=True)
    sns.heatmap(cr, cmap='Purples', annot=True, linecolor='white', linewidths=0.5).xaxis.tick_top()

def clf_plot(y_pred) :
    '''
    1) Ploting Confusion Matrix
    2) Plotting Classification Report'''
    cm = metrics.confusion_matrix(y_test, y_pred)
    cr = pd.DataFrame(metrics.classification_report(y_test, y_pred, digits=3, output_dict=True)).T
    cr.drop(columns='support', inplace=True)

    fig, ax = plt.subplots(1, 2, figsize=(15, 5))

    ax[0] = sns.heatmap(cm, annot=True, fmt='', cmap="Purples", ax=ax[0])
    ax[0].set_xlabel('Prediced labels', fontsize=18)
    ax[0].set_ylabel('True labels', fontsize=18)
    ax[0].set_title('Confusion Matrix', fontsize=25)

    unique_labels = sorted(set(y_test.unique()) | set(y_pred))

    ax[0].xaxis.set_ticklabels(unique_labels)
    ax[0].yaxis.set_ticklabels(unique_labels)

    ax[1] = sns.heatmap(cr, cmap='Purples', annot=True, linecolor='white', linewidths=0.5, ax=ax[1])
    ax[1].xaxis.tick_top()
    ax[1].set_title('Classification Report', fontsize=25)
    plt.show()

data_train.quality.value_counts()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)

"""## RandomForestClassifier"""

parameters = {
    'n_estimators' : [50, 150, 500],
    'criterion' : ['gini', 'entropy', 'log_loss'],
    'max_features' : ['sqrt', 'log2']
}

rf = RandomForestClassifier(n_jobs=-1)
rf_cv = GridSearchCV(estimator=rf, cv=6, param_grid=parameters).fit(X_train, y_train)

print('Tuned hyper parameters : ', rf_cv.best_params_)
print('accuracy : ', rf_cv.best_score_)

rf = RandomForestClassifier(**rf_cv.best_params_).fit(X_train, y_train)

y_pred_rf = rf.predict(X_test)

rf_score = round(rf.score(X_test, y_test), 3)
print('RandomForestClassifier score : ', rf_score)

y_test.value_counts()

"""tidak ada satupun data dengan label 3 di y_test"""

clf_plot(y_pred_rf)

"""**Evaluasi Confusion Matrix**

- 5 benar 67 → (13 salah ke kelas 6)
- 6	benar 46 → (19 salah ke 5, 3 salah ke 7)
- 7 benar 9	 → (9 salah ke 6, 1 salah ke 5)
- 4 benar 0  → (2 salah ke kelas 5)
- 8	benar 0 → (2 salah ke kelas 6, 1 salah ke kelas 7)

**Kinerja Umum Model**

- Akurasi keseluruhan: 70,9%

Model memiliki performa yang cukup baik secara keseluruhan, dengan 70,9% prediksi yang benar.

- Macro avg dan Weighted avg f1-score:

1. Macro avg: 0.4 → Rendah, menunjukkan ketidakseimbangan performa antar kelas.

2. Weighted avg: 0.69 → Lebih tinggi karena kelas dominan (misalnya label 5 dan 6) memiliki performa yang baik dan bobot yang besar.

## KNeighborsClassifier
"""

parameters = {
    'n_neighbors' : list(np.arange(3, 50, 2)),
    'weights': ['uniform', 'distance'],
    'p' : [1, 2, 3, 4]
}

knn = KNeighborsClassifier()
knn_cv = GridSearchCV(estimator=knn, cv=6, param_grid=parameters).fit(X_train, y_train)

print('Tuned hyper parameters : ', knn_cv.best_params_)
print('accuracy : ', knn_cv.best_score_)

knn = KNeighborsClassifier(**knn_cv.best_params_).fit(X_train, y_train)

y_pred_knn = knn_cv.predict(X_test)

knn_score = round(knn.score(X_test, y_test), 3)
print('KNeighborsClassifier Score :', knn_score)

clf_plot(y_pred_knn)

"""**Evaluasi Confusion Matrix**

- 5 benar 56 → (24 salah ke kelas 6)
- 6	benar 40 → (22 salah ke 5, 6 salah ke 7)
- 7 benar 9	 → (10 salah ke 6)
- 4 & 8	Jumlah sangat kecil → Prediksi salah semua

**Classification Report**

- Kelas 5 diprediksi paling baik (precision, recall, dan f1 tinggi).
- Kelas 4 dan 8 gagal dikenali — kemungkinan besar karena sangat sedikit datanya.
- F1-score macro average rendah (0.35) → artinya secara rata-rata model buruk pada kelas minoritas.
- Weighted avg lebih tinggi (0.60) karena kelas mayoritas lebih dominan dan lebih mudah diprediksi.

## DecisionTreeClassifier
"""

parameters = {
    'criterion' : ['gini', 'entropy', 'log_loss'],
    'splitter' : ['best', 'random'],
    'max_depth' : list(np.arange(4, 30, 1))
        }

tree = DecisionTreeClassifier()
tree_cv = GridSearchCV(estimator=tree, cv=6, param_grid=parameters).fit(X_train, y_train)

print('Tuned hyper parameters : ', tree_cv.best_params_)
print('accuracy : ', tree_cv.best_score_)

tree = DecisionTreeClassifier(**tree_cv.best_params_).fit(X_train, y_train)

y_pred_tree = tree.predict(X_test)

tree_score = round(tree.score(X_test, y_test), 3)
print('DecisionTreeClassifier Score : ', tree_score)

clf_plot(y_pred_tree)

"""**Evaluasi Confusion Matrix**

- kelas 5 benar 57
- kelas 6	benar 31
- kelas 7 benar 4
- kelas 4 benar 0  
- kelas 8	benar 0

**Kinerja Umum Model**

- Akurasi keseluruhan: 53% → artinya hanya sekitar setengah dari prediksi yang tepat

- Macro avg dan Weighted avg f1-score:

1. Macro avg: 0.28 → menunjukkan bahwa model sangat lemah dalam memprediksi kelas minoritas (karena semua kelas diberi bobot sama).

2. Weighted avg: 0.53 → karena dipengaruhi oleh jumlah data di masing-masing kelas, terutama kelas mayoritas (kelas 5 dan 6).

## LogisticRegression
"""

parameters = {
    'C' : [0.001, 0.01, 0.1, 1.0, 10, 100, 1000],
    'class_weight' : ['balanced'],
    'solver' : ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']
}

lr = LogisticRegression()
lr_cv = GridSearchCV(estimator=lr, param_grid=parameters, cv=6).fit(X_train, y_train)

print('Tuned hyper parameters : ', lr_cv.best_params_)
print('accuracy : ', lr_cv.best_score_)

lr = LogisticRegression(**lr_cv.best_params_).fit(X_train, y_train)

y_pred_lr = lr.predict(X_test)

lr_score = round(lr.score(X_test, y_test), 3)
print('LogisticRegression score : ', lr_score)

clf_plot(y_pred_lr)

"""**Evaluasi Confusion Matrix**

- kelas 5 benar 70
- kelas 6	benar 29
- kelas 7 benar 0
- kelas 4 benar 0  
- kelas 8	benar 0

**Kinerja Umum Model**

- Akurasi keseluruhan: 57% → artinya hanya sekitar setengah dari prediksi yang tepat

- Macro avg dan Weighted avg f1-score:

1. Macro avg: 0.24 → menunjukkan bahwa model sangat lemah dalam memprediksi kelas minoritas (karena semua kelas diberi bobot sama).

2. Weighted avg: 0.52 → karena dipengaruhi oleh jumlah data di masing-masing kelas, terutama kelas mayoritas (kelas 5 dan 6).

## Result
"""

result = pd.DataFrame({
    'Algorithm' : ['RandomForestClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'LogisticRegression'],
    'Score' : [rf_score, knn_score, tree_score, lr_score]
})

result.sort_values(by='Score', inplace=True)

sns.set_palette("Purples")
fig, ax = plt.subplots(1, 1, figsize=(15, 5))

sns.barplot(x='Algorithm', y='Score', data=result)
ax.bar_label(ax.containers[0], fmt='%.3f')
ax.set_xticklabels(labels=result.Algorithm, rotation=300)
plt.show()

"""Berdasarkan dari grafik diatas, best algorithm base on Score adalah :
**RandomForestClassifier**

jadi, kita memilih **RandomForestClassifier**

## Final Modeling
"""

# Model
rf = RandomForestClassifier(**rf_cv.best_params_)

rf.fit(X, y)

"""# **Deployment Model**

## Simpan Model dan Scaler
"""

import joblib

joblib.dump(MinMaxScaler().fit(X_temp), '/content/drive/MyDrive/scaler.pkl')
joblib.dump(rf, '/content/drive/MyDrive/classification_model.pkl')

"""## Load Testing Data"""

data_test = pd.read_csv('/content/drive/MyDrive/data_testing.csv')
data_test.head()

ids = data_test['Id']

"""memisahkan kolom Id agar tidak ikut diprediksi"""

X_val = data_test.drop(columns=['Id'])

X_val.rename(columns = {"fixed acidity": "fixed_acidity",
                       "volatile acidity": "volatile_acidity",
                       "citric acid": "citric_acid",
                       "residual sugar": "residual_sugar",
                       "chlorides": "chlorides",
                       "free sulfur dioxide": "free_sulfur_dioxide",
                       "total sulfur dioxide": "total_sulfur_dioxide"},
            inplace = True)

scaler = joblib.load('/content/drive/MyDrive/scaler.pkl')
X_val_scaled = scaler.transform(X_val)

"""nama kolom disesuaikan agar match dengan fitur saat training.

Memuat scaler yang sudah dilatih dari data train, lalu melakukan transformasi ke data testing.

## Predict
"""

model = joblib.load('/content/drive/MyDrive/classification_model.pkl')

# Predict
y_test_pred = model.predict(X_val_scaled)

output = pd.DataFrame({
    'Id': ids,
    'quality': y_test_pred
})

output.to_csv('/content/drive/MyDrive/hasilprediksi_010.csv', index=False)